{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import transformers\n",
    "from transformers import BertModel, BertConfig, BertTokenizer, AdamW, get_linear_schedule_with_warmup, BertForSequenceClassification\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "MAX_LEN = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('mymodel')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single GPU\n"
     ]
    }
   ],
   "source": [
    "class_names = ['negative', 'positive']\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(torch.cuda.device_count(), \" GPUs\")\n",
    "    model = nn.DataParallel(model)\n",
    "else:\n",
    "    print(\"Single GPU\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2690, 0.7310]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "Review text: 服務人員有禮貌，親切，房間還滿乾淨的 床很舒服\n",
      "Sentiment  : positive\n",
      "prediction : 1\n"
     ]
    }
   ],
   "source": [
    "review_text = df.sample(1).iloc[0].content\n",
    "review_label= df.sample(1).iloc[0].label\n",
    "\n",
    "encoded_review = tokenizer.encode_plus(\n",
    "  review_text,\n",
    "  max_length=MAX_LEN,\n",
    "  truncation=True,\n",
    "  add_special_tokens=True,\n",
    "  return_token_type_ids=False,\n",
    "  pad_to_max_length=True,\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',\n",
    ")\n",
    "\n",
    "input_ids = encoded_review['input_ids'].to(device)\n",
    "attention_mask = encoded_review['attention_mask'].to(device)\n",
    "\n",
    "output = model(input_ids, attention_mask)\n",
    "output = output[0]\n",
    "output = F.softmax(output, dim=1)\n",
    "_, prediction = torch.max(output, dim=1)\n",
    "\n",
    "print(F.softmax(output, dim=1))\n",
    "print(f'Review text: {review_text}')\n",
    "print(f'Sentiment  : {class_names[prediction]}')\n",
    "print(f'prediction : {prediction.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp] *",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
