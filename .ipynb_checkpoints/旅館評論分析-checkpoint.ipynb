{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup, BertForSequenceClassification\n",
    "\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "RANDOM_SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncolumn_names = [\\'content\\', \\'label\\', \\'hotel_name\\']\\ndf = pd.DataFrame(columns = column_names)\\n\\nroot_dir = \"./Crawler/CrawlerToBooking/\"\\ndirectories = [\\'negativeReviews\\', \\'positiveReviews\\']\\n\\nfor label, directory in enumerate(directories):\\n    txt_path = os.path.join(root_dir, directory)\\n    for filename in os.listdir(txt_path):\\n        hotel_name = os.path.splitext(filename)[0]\\n        with open(os.path.join(txt_path, filename)) as f:\\n            content = f.read()\\n            dict_new = {\"content\":content.strip().replace(\"\\n\",\"\"), \"label\":str(label), \"hotel_name\":hotel_name}\\n            df = df.append(dict_new, ignore_index=True)\\ndf.to_csv(\"reviews.csv\", index=False)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "column_names = ['content', 'label', 'hotel_name']\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "root_dir = \"./Crawler/CrawlerToBooking/\"\n",
    "directories = ['negativeReviews', 'positiveReviews']\n",
    "\n",
    "for label, directory in enumerate(directories):\n",
    "    txt_path = os.path.join(root_dir, directory)\n",
    "    for filename in os.listdir(txt_path):\n",
    "        hotel_name = os.path.splitext(filename)[0]\n",
    "        with open(os.path.join(txt_path, filename)) as f:\n",
    "            content = f.read()\n",
    "            dict_new = {\"content\":content.strip().replace(\"\\n\",\"\"), \"label\":str(label), \"hotel_name\":hotel_name}\n",
    "            df = df.append(dict_new, ignore_index=True)\n",
    "df.to_csv(\"reviews.csv\", index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv('reviews.csv')\n",
    "fullsize = len(original_df)\n",
    "datasize = int(fullsize * 0.1)\n",
    "df = original_df.sample(datasize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-chinese'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_txt = df.content[150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize(sample_txt)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(f' Sentence: {sample_txt}')\n",
    "print(f'   Tokens: {tokens}')\n",
    "print(f'Token IDs: {token_ids}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "  sample_txt,\n",
    "  max_length=512,\n",
    "  truncation=True,\n",
    "  add_special_tokens=True, \n",
    "  return_token_type_ids=False,\n",
    "  pad_to_max_length=True,\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',  \n",
    ")\n",
    "\n",
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(encoding['input_ids'][0]))\n",
    "# encoding['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(encoding['attention_mask'][0]))\n",
    "# encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPReviewDataset(Dataset):\n",
    "\n",
    "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
    "    self.reviews = reviews\n",
    "    self.targets = targets\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.reviews)\n",
    "  \n",
    "  def __getitem__(self, item):\n",
    "    review = str(self.reviews[item])\n",
    "    target = self.targets[item]\n",
    "\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      review,\n",
    "      add_special_tokens=True,\n",
    "      truncation=True,\n",
    "      max_length=self.max_len,\n",
    "      return_token_type_ids=False,\n",
    "      pad_to_max_length=True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    return {\n",
    "      'review_text': review,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "      'targets': torch.tensor(target, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.1, random_state=RANDOM_SEED)\n",
    "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240189    1\n",
       "40320     0\n",
       "39634     0\n",
       "189956    1\n",
       "120080    0\n",
       "271098    1\n",
       "267907    1\n",
       "189705    1\n",
       "279780    1\n",
       "165281    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.label.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "  ds = GPReviewDataset(\n",
    "    reviews=df.content.to_numpy(),\n",
    "    targets=df.label.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(train_data_loader))\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 384])\n",
      "torch.Size([8, 384])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(data['input_ids'].shape)\n",
    "print(data['attention_mask'].shape)\n",
    "print(data['targets'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "# bert_model = BertForSequenceClassification.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_state, pooled_output = bert_model(\n",
    "  input_ids=encoding['input_ids'], \n",
    "  attention_mask=encoding['attention_mask']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "  \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.bert(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "        )\n",
    "        output = self.drop(pooled_output)\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single GPU\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "class_names = ['negative', 'positive']\n",
    "model = SentimentClassifier(len(class_names))\n",
    "model = model.to(device)\n",
    "'''\n",
    "class_names = ['negative', 'positive']\n",
    "model = SentimentClassifier(len(class_names))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(torch.cuda.device_count(), \" GPUs\")\n",
    "    model = nn.DataParallel(model)\n",
    "else:\n",
    "    print(\"Single GPU\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = data['input_ids'].to(device)\n",
    "attention_mask = data['attention_mask'].to(device)\n",
    "\n",
    "print(input_ids.shape) # batch size x seq length\n",
    "print(attention_mask.shape) # batch size x seq length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.softmax(model(input_ids, attention_mask), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "  model, \n",
    "  data_loader, \n",
    "  loss_fn, \n",
    "  optimizer, \n",
    "  device, \n",
    "  scheduler, \n",
    "  n_examples\n",
    "):\n",
    "  model = model.train()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  \n",
    "  for d in data_loader:\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    targets = d[\"targets\"].to(device)\n",
    "\n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    loss = loss_fn(outputs, targets)\n",
    "\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "  model = model.eval()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "      loss = loss_fn(outputs, targets)\n",
    "\n",
    "      correct_predictions += torch.sum(preds == targets)\n",
    "      losses.append(loss.item())\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 0.2407153598585289 accuracy 0.936483673734877\n",
      "Val   loss 0.1764667292830543 accuracy 0.9537470725995316\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 0.1630747225452951 accuracy 0.9622414465981527\n",
      "Val   loss 0.19641910138252738 accuracy 0.9590163934426229\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 0.1372709859939802 accuracy 0.968453232730584\n",
      "Val   loss 0.18683151583944527 accuracy 0.9631147540983607\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 0.11904158942865617 accuracy 0.9727787173149472\n",
      "Val   loss 0.18716589350984475 accuracy 0.961943793911007\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 0.10630830606633679 accuracy 0.9760634838038246\n",
      "Val   loss 0.19831577535266073 accuracy 0.961943793911007\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 0.09488840514947113 accuracy 0.9786978014830232\n",
      "Val   loss 0.1978608908601732 accuracy 0.9672131147540983\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss 0.08150358283049142 accuracy 0.9814622089241576\n",
      "Val   loss 0.2323104728048093 accuracy 0.9631147540983607\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train loss 0.07599158042753028 accuracy 0.9825029270196435\n",
      "Val   loss 0.23126507651443792 accuracy 0.9607728337236534\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Train loss 0.06807233883226901 accuracy 0.9840314817223884\n",
      "Val   loss 0.2315655147534943 accuracy 0.9601873536299765\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Train loss 0.061555981161179454 accuracy 0.985234812020294\n",
      "Val   loss 0.2255910892631406 accuracy 0.9613583138173302\n",
      "\n",
      "CPU times: user 1h 38min 18s, sys: 43min 17s, total: 2h 21min 35s\n",
      "Wall time: 2h 21min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    model,\n",
    "    train_data_loader,    \n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    device, \n",
    "    scheduler, \n",
    "    len(df_train)\n",
    "  )\n",
    "\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "  val_acc, val_loss = eval_model(\n",
    "    model,\n",
    "    val_data_loader,\n",
    "    loss_fn, \n",
    "    device, \n",
    "    len(df_val)\n",
    "  )\n",
    "\n",
    "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "  print()\n",
    "\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n",
    "  history['val_acc'].append(val_acc)\n",
    "  history['val_loss'].append(val_loss)\n",
    "\n",
    "  if val_acc > best_accuracy:\n",
    "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history['train_acc'], label='train accuracy')\n",
    "plt.plot(history['val_acc'], label='validation accuracy')\n",
    "\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['negative', 'positive']\n",
    "model = SentimentClassifier(len(class_names))\n",
    "model.load_state_dict(torch.load('best_model_state.bin'))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9619660620245758"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc, _ = eval_model(\n",
    "    model,\n",
    "    test_data_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(df_test)\n",
    ")\n",
    "\n",
    "test_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "  model = model.eval()\n",
    "  \n",
    "  review_texts = []\n",
    "  predictions = []\n",
    "  prediction_probs = []\n",
    "  real_values = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "\n",
    "      texts = d[\"review_text\"]\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "      probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "      review_texts.extend(texts)\n",
    "      predictions.extend(preds)\n",
    "      prediction_probs.extend(probs)\n",
    "      real_values.extend(targets)\n",
    "\n",
    "  predictions = torch.stack(predictions).cpu()\n",
    "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "  real_values = torch.stack(real_values).cpu()\n",
    "  return review_texts, predictions, prediction_probs, real_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
    "  model,\n",
    "  test_data_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.97      0.95       707\n",
      "    positive       0.98      0.96      0.97      1002\n",
      "\n",
      "    accuracy                           0.96      1709\n",
      "   macro avg       0.96      0.96      0.96      1709\n",
      "weighted avg       0.96      0.96      0.96      1709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "\n",
    "review_text = y_review_texts[idx]\n",
    "true_sentiment = y_test[idx]\n",
    "pred_df = pd.DataFrame({\n",
    "  'class_names': class_names,\n",
    "  'values': y_pred_probs[idx]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "地點不錯，離三多商圈捷運站不遠，一路上有超商以及小吃店。床鋪偏硬，喜歡。服務人員熱情有禮貌。給免費升級了海景房，正對著高雄港，也可遠眺西子灣\n",
      "、壽山。市景也很不錯。下次來高雄還會選擇住在85大樓。\n",
      "\n",
      "True sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "from textwrap import wrap\n",
    "print(\"\\n\".join(wrap(review_text)))\n",
    "print()\n",
    "print(f'True sentiment: {class_names[true_sentiment]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n",
      "tensor([[2.7040e-04, 9.9973e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "Review text: 早餐品質真的中間偏下 頗失望的\n",
      "Sentiment  : positive\n",
      "prediction : tensor([1], device='cuda:0')\n",
      "groundtruth : 0\n"
     ]
    }
   ],
   "source": [
    "review_text = df.sample(1).iloc[0].content\n",
    "review_label= df.sample(1).iloc[0].label\n",
    "\n",
    "encoded_review = tokenizer.encode_plus(\n",
    "  review_text,\n",
    "  max_length=MAX_LEN,\n",
    "  truncation=True,\n",
    "  add_special_tokens=True,\n",
    "  return_token_type_ids=False,\n",
    "  pad_to_max_length=True,\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',\n",
    ")\n",
    "\n",
    "input_ids = encoded_review['input_ids'].to(device)\n",
    "attention_mask = encoded_review['attention_mask'].to(device)\n",
    "\n",
    "# output = model(input_ids, attention_mask)\n",
    "print(output.shape)\n",
    "_, prediction = torch.max(output, dim=1)\n",
    "print(F.softmax(output, dim=1))\n",
    "print(f'Review text: {review_text}')\n",
    "print(f'Sentiment  : {class_names[prediction]}')\n",
    "print(f'prediction : {str(prediction)}')\n",
    "print(f'groundtruth : {str(review_label)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"wholemodel.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 9.38 GiB already allocated; 15.62 MiB free; 9.81 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-c739f74f0df2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-64dc92491dcb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     10\u001b[0m     _, pooled_output = self.bert(\n\u001b[1;32m     11\u001b[0m       \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m       \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     14\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_extended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m         )\n\u001b[1;32m    764\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m                 )\n\u001b[1;32m    441\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    369\u001b[0m     ):\n\u001b[1;32m    370\u001b[0m         self_attention_outputs = self.attention(\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         )\n\u001b[1;32m    373\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    313\u001b[0m     ):\n\u001b[1;32m    314\u001b[0m         self_outputs = self.self(\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         )\n\u001b[1;32m    317\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 9.38 GiB already allocated; 15.62 MiB free; 9.81 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "my_loader = create_data_loader(df.sample(500), tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "testdata = next(iter(my_loader))\n",
    "targets = testdata[\"targets\"].to(device)\n",
    "input_ids = testdata['input_ids'].to(device)\n",
    "attention_mask = testdata['attention_mask'].to(device)\n",
    "outputs = model(input_ids, attention_mask)\n",
    "loss = loss_fn(outputs, targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp] *",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
